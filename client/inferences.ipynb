{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import requests\n",
    "import tritonclient.http as httpclient\n",
    "import tritonclient.grpc as grpcclient\n",
    "from tritonclient.grpc import service_pb2, service_pb2_grpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triton Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_preprocessing(image: cv2.Mat) -> np.ndarray:\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (640, 480), (123.68, 116.78, 103.94), True, False)\n",
    "    blob = np.transpose(blob, (0, 2, 3, 1))  # (1, 3, 480, 640)\n",
    "    return blob\n",
    "\n",
    "def detection_postprocessing(scores, geometry, preprocessed_image):\n",
    "    def fourPointsTransform(frame, vertices):  # (480, 640, 3) / [[x1, y1], [x2, y2], [x1, y2], [x2, y1]]\n",
    "        vertices = np.asarray(vertices)\n",
    "        outputSize = (100, 32)\n",
    "        targetVertices = np.array(\n",
    "            [\n",
    "                [0, outputSize[1] - 1],\n",
    "                [0, 0],\n",
    "                [outputSize[0] - 1, 0],\n",
    "                [outputSize[0] - 1, outputSize[1] - 1],\n",
    "            ],\n",
    "        dtype=\"float32\") # (4, 2)\n",
    "        rotationMatrix = cv2.getPerspectiveTransform(vertices, targetVertices) # (3, 3)\n",
    "        result = cv2.warpPerspective(frame, rotationMatrix, outputSize)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_INTERMEDIATE_IMAGES = False\n",
    "\n",
    "def detection_postprocessing(scores, geometry, preprocessed_image):\n",
    "    def fourPointsTransform(frame, vertices):  # (480, 640, 3) / [[x1, y1], [x2, y2], [x1, y2], [x2, y1]]\n",
    "        vertices = np.asarray(vertices)\n",
    "        outputSize = (100, 32)\n",
    "        targetVertices = np.array(\n",
    "            [\n",
    "                [0, outputSize[1] - 1],\n",
    "                [0, 0],\n",
    "                [outputSize[0] - 1, 0],\n",
    "                [outputSize[0] - 1, outputSize[1] - 1],\n",
    "            ],\n",
    "            dtype=\"float32\",\n",
    "        ) # (4, 2)\n",
    "\n",
    "        rotationMatrix = cv2.getPerspectiveTransform(vertices, targetVertices) # (3, 3)\n",
    "        result = cv2.warpPerspective(frame, rotationMatrix, outputSize)\n",
    "        return result\n",
    "\n",
    "    def decodeBoundingBoxes(scores, geometry, scoreThresh=0.5):\n",
    "        detections = []\n",
    "        confidences = []\n",
    "\n",
    "        # CHECK DIMENSIONS AND SHAPES OF geometry AND scores\n",
    "        assert len(scores.shape) == 4, \"Incorrect dimensions of scores\"\n",
    "        assert len(geometry.shape) == 4, \"Incorrect dimensions of geometry\"\n",
    "        assert scores.shape[0] == 1, \"Invalid dimensions of scores\"\n",
    "        assert geometry.shape[0] == 1, \"Invalid dimensions of geometry\"\n",
    "        assert scores.shape[1] == 1, \"Invalid dimensions of scores\"\n",
    "        assert geometry.shape[1] == 5, \"Invalid dimensions of geometry\"\n",
    "        assert (\n",
    "            scores.shape[2] == geometry.shape[2]\n",
    "        ), \"Invalid dimensions of scores and geometry\"\n",
    "        assert (\n",
    "            scores.shape[3] == geometry.shape[3]\n",
    "        ), \"Invalid dimensions of scores and geometry\"\n",
    "        \n",
    "        height = scores.shape[2]\n",
    "        width = scores.shape[3]\n",
    "        \n",
    "        for y in range(0, height):\n",
    "            # Extract data from scores\n",
    "            scoresData = scores[0][0][y]   # (160, )\n",
    "            x0_data = geometry[0][0][y]    # (160, )\n",
    "            x1_data = geometry[0][1][y]    # (160, ) \n",
    "            x2_data = geometry[0][2][y]    # (160, )\n",
    "            x3_data = geometry[0][3][y]    # (160, )\n",
    "            anglesData = geometry[0][4][y] # (160, )\n",
    "            \n",
    "            for x in range(0, width):\n",
    "                score = scoresData[x]      # (1, )\n",
    "\n",
    "                # If score is lower than threshold score, move to next x\n",
    "                if score < scoreThresh:\n",
    "                    continue\n",
    "\n",
    "                # Calculate offset\n",
    "                offsetX = x * 4.0          # x,y are indices of width, height\n",
    "                offsetY = y * 4.0\n",
    "                angle = anglesData[x]      # (1, )\n",
    "\n",
    "                # Calculate cos and sin of angle\n",
    "                cosA = math.cos(angle)\n",
    "                sinA = math.sin(angle)\n",
    "                h = x0_data[x] + x2_data[x]\n",
    "                w = x1_data[x] + x3_data[x]\n",
    "\n",
    "                # Calculate offset\n",
    "                offset = [\n",
    "                    offsetX + cosA * x1_data[x] + sinA * x2_data[x],\n",
    "                    offsetY - sinA * x1_data[x] + cosA * x2_data[x],\n",
    "                ]\n",
    "\n",
    "                # Find points for rectangle\n",
    "                p1 = (-sinA * h + offset[0], -cosA * h + offset[1])\n",
    "                p3 = (-cosA * w + offset[0], sinA * w + offset[1])\n",
    "                center = (0.5 * (p1[0] + p3[0]), 0.5 * (p1[1] + p3[1]))\n",
    "                detections.append((center, (w, h), -1 * angle * 180.0 / math.pi))\n",
    "                confidences.append(float(score))\n",
    "\n",
    "        # Return detections and confidences\n",
    "        return [detections, confidences]\n",
    "\n",
    "    scores = scores.transpose(0, 3, 1, 2)           # (1, 1, 120, 160)\n",
    "    geometry = geometry.transpose(0, 3, 1, 2)       # (1, 5, 120, 160)\n",
    "    frame = np.squeeze(preprocessed_image, axis=0)  # (480, 640, 3)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # (480, 640, 3)\n",
    "    [boxes, confidences] = decodeBoundingBoxes(scores, geometry)    # [list: 248 of ((center_x, center_y), (w,h), angle), list: 248]\n",
    "    indices = cv2.dnn.NMSBoxesRotated(boxes, confidences, 0.5, 0.4) # Non-max suppression -> (1)\n",
    "    \n",
    "    cropped_list = []\n",
    "    count = 0\n",
    "    for i in indices:\n",
    "        # get 4 corners of the rotated rect\n",
    "        count += 1\n",
    "        vertices = cv2.boxPoints(boxes[i])  # [[x1, y1], [x2, y2], [x1, y2], [x2, y1]]\n",
    "        cropped = fourPointsTransform(frame, vertices) # (32, 100, 3)\n",
    "        cropped = np.expand_dims(cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY), axis=0) # (1, 32, 100)\n",
    "        cropped_list.append(((cropped / 255.0) - 0.5) * 2) # normalize\n",
    "        \n",
    "    cropped_arr = np.stack(cropped_list, axis=0) # (1, 1, 32, 100)\n",
    "    return cropped_arr[None, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition_postprocessing(scores: np.ndarray) -> str:\n",
    "    text = \"\"\n",
    "    alphabet = \"0123456789abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "    scores = np.transpose(scores, (1, 0, 2))\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        c = np.argmax(scores[i][0])\n",
    "        if c != 0:\n",
    "            text += alphabet[c - 1]\n",
    "        else:\n",
    "            text += \"-\"\n",
    "    # adjacent same letters as well as background text must be removed\n",
    "    # to get the final output\n",
    "    char_list = []\n",
    "    for i, char in enumerate(text):\n",
    "        if char != \"-\" and (not (i > 0 and char == text[i - 1])):\n",
    "            char_list.append(char)\n",
    "    return \"\".join(char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Setting up client\n",
    "    client = httpclient.InferenceServerClient(url=\"localhost:8000\")\n",
    "\n",
    "    # Read image and create input object\n",
    "    raw_image = cv2.imread(\"./inputs/sample.jpg\")           # (4000, 3000, 3)\n",
    "    preprocessed_image = detection_preprocessing(raw_image) # (1, 480, 640, 3)\n",
    "\n",
    "    detection_input = httpclient.InferInput(\n",
    "        \"input_images:0\", preprocessed_image.shape, datatype=\"FP32\"\n",
    "    )\n",
    "    detection_input.set_data_from_numpy(preprocessed_image, binary_data=True)\n",
    "\n",
    "    # # Query the server\n",
    "    detection_response = client.infer(\n",
    "        model_name=\"text_detection\", inputs=[detection_input]\n",
    "    )\n",
    "\n",
    "    # Process responses from detection model\n",
    "    scores = detection_response.as_numpy(\"feature_fusion/Conv_7/Sigmoid:0\")         # (1, 120, 160, 1) down 4\n",
    "    geometry = detection_response.as_numpy(\"feature_fusion/concat_3:0\")             # (1, 120, 160, 5)\n",
    "    cropped_images = detection_postprocessing(scores, geometry, preprocessed_image) # (1, 32, 100)\n",
    "\n",
    "    # Create input object for recognition model\n",
    "    recognition_input = httpclient.InferInput(\n",
    "        \"input.1\", cropped_images.shape, datatype=\"FP32\"\n",
    "    )\n",
    "    recognition_input.set_data_from_numpy(cropped_images, binary_data=True)\n",
    "\n",
    "    # # Query the server\n",
    "    recognition_response = client.infer(\n",
    "        model_name=\"text_recognition\", inputs=[recognition_input]\n",
    "    )\n",
    "\n",
    "    # Process response from recognition model\n",
    "    final_text = recognition_postprocessing(recognition_response.as_numpy(\"308\"))\n",
    "    print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRPC for Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TritonClient:\n",
    "    def __init__(self, url=\"localhost:8001\"):\n",
    "        self.url = url\n",
    "        self.client = grpcclient.InferenceServerClient(url=self.url)\n",
    "        \n",
    "    def inference(self, model_name=None, input_name=None, input_dtype=None, path=None):\n",
    "        assert model_name is not None, \"Insert the model for inference\"\n",
    "        assert input_name is not None, \"Insert input name for inference\"\n",
    "        assert input_dtype is not None, \"Insert data type for inference\"\n",
    "        assert path is not None, \"Insert one image for inference\"\n",
    "        \n",
    "        image_data = np.fromfile(path, dtype=\"uint8\")\n",
    "        image_data = np.expand_dims(image_data, axis=0)\n",
    "        \n",
    "        inputs = [grpcclient.InferInput(input_name, image_data.shape, input_dtype)]\n",
    "        inputs[0].set_data_from_numpy(image_data)\n",
    "        \n",
    "        results = self.client.infer(model_name=model_name, inputs=inputs)\n",
    "        output_data = results.as_numpy(\"recognized_text\").astype(str)\n",
    "        print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    triton_client = TritonClient()\n",
    "    triton_client.inference(\n",
    "        model_name=\"ensemble_model\",\n",
    "        input_name=\"input_image\",\n",
    "        input_dtype=\"UINT8\",\n",
    "        path=\"inputs/sample.jpg\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_preprocessing(image: cv2.Mat) -> np.ndarray:\n",
    "    inpWidth = 640\n",
    "    inpHeight = 480\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (inpWidth, inpHeight), (123.68, 116.78, 103.94), False, False)\n",
    "    blob = np.transpose(blob, (0, 2, 3, 1))\n",
    "    return blob\n",
    "\n",
    "image = cv2.imread(\"inputs/sample.jpg\")\n",
    "image = detection_preprocessing(image)\n",
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(image) -> np.ndarray:\n",
    "    image = np.array(image.resize((640, 480)))\n",
    "    image = image - np.array([103.94, 123.68, 116.78]).reshape(1,1,3)\n",
    "    image = image.astype(np.float32)[None, ...]\n",
    "    return image\n",
    "\n",
    "image = Image.open(\"inputs/sample.jpg\")\n",
    "image = image_loader(image)\n",
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTTP Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TritonClientInference:\n",
    "    def __init__(self):\n",
    "        self.url = \"http://localhost:8000/v2/models/classification/infer\"\n",
    "    \n",
    "    def inference(self, input_data):\n",
    "        inputs = [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"shape\": input_data.shape,\n",
    "                \"datatype\": \"FP32\",\n",
    "                \"data\": input_data.tolist()\n",
    "            }\n",
    "        ]\n",
    "        outputs = [{\"name\": \"output\"}]\n",
    "        \n",
    "        request_payload = {\n",
    "            \"inputs\": inputs,\n",
    "            \"outputs\": outputs\n",
    "        }\n",
    "        response = requests.post(self.url, json=request_payload)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            output_data = np.array(response_json[\"outputs\"][0][\"data\"]).reshape(response_json[\"outputs\"][0][\"shape\"])\n",
    "            print(\"Output Data: \", output_data.shape)\n",
    "            \n",
    "        else:\n",
    "            print(\"Request failed with status code: \", response.status_code)\n",
    "            print(\"Response: \", response.text)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = TritonClientInference()\n",
    "    input_data = np.zeros((1, 3, 224, 224), dtype=np.float32)\n",
    "    client.inference(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRPC Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TritonClient:\n",
    "    def __init__(self):\n",
    "        self.url = \"localhost:8001\"\n",
    "        self.client = grpcclient.InferenceServerClient(url=self.url)\n",
    "        \n",
    "    def infer(self, model_name, input_data):\n",
    "        inputs = []\n",
    "        input_tensor = grpcclient.InferInput(\"input\", input_data.shape, \"FP32\")\n",
    "        input_tensor.set_data_from_numpy(input_data)\n",
    "        inputs.append(input_tensor)\n",
    "        \n",
    "        outputs = []\n",
    "        output_tensor = grpcclient.InferRequestedOutput(\"output\")\n",
    "        outputs.append(output_tensor)\n",
    "        \n",
    "        start = time.time()\n",
    "        response = self.client.infer(model_name=model_name, inputs=inputs, outputs=outputs)\n",
    "        print(\"Model inference time\", (time.time() - start)*1000, \"ms\")\n",
    "        \n",
    "        output_data = response.as_numpy(\"output\")\n",
    "        return output_data\n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    model_name = \"classification\"\n",
    "    input_data = np.zeros((1, 3, 224, 224), dtype=np.float32)\n",
    "    \n",
    "    triton_client = TritonClient()\n",
    "    start = time.time()\n",
    "    output = triton_client.infer(model_name, input_data)\n",
    "    print(\"Total call inference time\", (time.time() - start)*1000, \"ms\")\n",
    "    print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
